# -*- coding: utf-8 -*-
"""with_chamfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RL95DZZ2nk2cMxA80NTglHFos2T4mhuP

# PointNet

This is an implementation of [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593) using PyTorch.

## Getting started

Don't forget to turn on GPU if you want to start training directly. 


**Runtime** -> **Change runtime type**-> **Hardware accelerator**
"""

!pip install path.py;
from path import Path

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from transforms import Normalize, PointSampler, RandomNoise, RandRotation_z, ToTensor
from dataset import PointCloudData
from model import PointNet
import open3d as o3d
import random
import os
from path import Path
import argparse
import sklearn
from sklearn.metrics import recall_score, precision_score, confusion_matrix
from tqdm import tqdm
from utils import plot_class_wise_scores

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#pip install open3d

random.seed = 42

"""Download the [dataset](http://3dvision.princeton.edu/projects/2014/3DShapeNets/) directly to the Google Colab Runtime. It comprises 10 categories, 3,991 models for training and 908 for testing."""

#!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip

#!unzip -q ModelNet10.zip;

pip install chamferdist

from chamferdist import ChamferDistance

path = Path("ModelNet10")

folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]
classes = {folder: i for i, folder in enumerate(folders)};
classes

"""This dataset consists ofÂ **.off** files that contain meshes represented by *vertices* and *triangular faces*. 

We will need a function to read this type of files:
"""

def read_off(file):
    if 'OFF' != file.readline().strip():
        raise('Not a valid OFF header')
    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])
    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]
    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]
    return verts, faces

with open(path/"bed/train/bed_0001.off", 'r') as f:
  verts, faces = read_off(f)

i,j,k = np.array(faces).T
x,y,z = np.array(verts).T

len(x)

#pip install git+'https://github.com/otaheri/chamfer_distance'





def fgsm_attack(model, criterion, point, labels, eps) :
    point.requires_grad = True
    outputs, _, _= model(point.transpose(1,2))
    model.zero_grad()
    loss = criterion(outputs, labels)
    loss.backward()
    attack_data = point + eps*point.grad.sign()
    return attack_data

def pertubation_point(point_cloud):
    x,y,z = point_cloud.shape
    epsilon = torch.empty(x,y,z)
    epsilon = nn.init.xavier_normal_(epsilon)
    pert_pc = torch.add(point_cloud,epsilon)
    return pert_pc

def attack(model, criterion, point, label, eps, k,attack_type, pointcloud_form=False):
    if attack_type =='fgsm':
        
        new_points = fgsm_attack(model, criterion, point, label, eps)
    else:
        new_points = pertubation_point(point)
    chamferDist = ChamferDistance()
    
    #dist_loss = (torch.mean(dist1)) + (torch.mean(dist2))
    #chamfer_loss.append(dist_loss)
    LL = labels.detach().cpu().numpy()[0]
    outputs, __, __ = model(new_points.transpose(1,2))
    _, preds = torch.max(outputs.data, 1)
    dist_forward.append(chamferDist(point, new_points).detach().cpu().item())
      
    if (pointcloud_form):
        for i in range(len(point)):
            pointcloud_vis = new_points[i].detach().cpu().numpy()
            pointcloud_vis = pointcloud_vis.reshape(-1,3)
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(pointcloud_vis)
            o3d.io.write_point_cloud("before_attack_new_pert_point_"+str(i)+"_"+str(k)+str(LL)+".ply",pcd)

    return preds,dist_forward

path = Path("ModelNet10")
train_transforms = transforms.Compose([
                PointSampler(1024),
                Normalize(),
                RandRotation_z(),
                RandomNoise(),
                ToTensor()
                ])

test_dataset = PointCloudData(path, True, "test", train_transforms)
model = PointNet()
model = model.train()
model = model.to(device)
model.load_state_dict(torch.load("./save.pth",map_location=torch.device('cpu')))
fgsm_dataloader = DataLoader(test_dataset, batch_size=24, shuffle=False)
criterion = nn.NLLLoss()
inv_classes = {i: cat for cat, i in test_dataset.classes.items()};

total_targets = torch.zeros((0))
total_preds = torch.zeros((0))
total_accu = 0
total_data_no = 0
dist_forward=[]
print("Attacking the pointnet using FGSM with epsilon ", 1e-3)
for i, data in enumerate(tqdm(fgsm_dataloader, position=0, leave=False)):
    labels = data['category']
    input_cloud = data['pointcloud']
    input_cloud = input_cloud.type(torch.FloatTensor)
    input_cloud = input_cloud.to(device)
    labels = labels.to(device)
    torch.cuda.empty_cache()
    preds,dists = attack(model, criterion, input_cloud, labels,eps=1e-3,k=i,attack_type='pert')
    #chamfer_loss.append(dists)
    #print(dist_forward)
    acc = torch.sum(preds == labels) / preds.shape[0]
    total_accu += acc.item() * preds.shape[0]
    total_data_no += preds.shape[0]
    print("Batch wise Accuarcy {0:.4f}".format(acc.item()*100))
    total_preds = torch.cat([total_preds, preds.detach().cpu().squeeze()], dim=0)
    total_targets = torch.cat([total_targets, labels.detach().cpu().squeeze()], dim=0)

total_targets = total_targets.detach().cpu().numpy()
total_preds = total_preds.detach().cpu().numpy()
confus_mat = confusion_matrix(total_targets, total_preds)
recall_sco = recall_score(total_targets, total_preds, average=None)
precision_sco = precision_score(total_targets, total_preds, average=None)
print("Accuracy: {0:.4f}".format(total_accu *100 / total_data_no))
plot_class_wise_scores(inv_classes, recall_sco, "recall scores")
plot_class_wise_scores(inv_classes, precision_sco, "precision scores")

dist_forward

